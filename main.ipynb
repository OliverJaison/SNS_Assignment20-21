{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs4\n",
    "from datetime import date\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import csv\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import InputLayer\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulls data from websites and stores them in csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data():\n",
    "    positive_cases_csv_URL = \"https://covid.ourworldindata.org/data/owid-covid-data.csv\"\n",
    "    req = requests.get(positive_cases_csv_URL)\n",
    "    URL_content = req.content\n",
    "    positive_cases_file = open(\"positive_cases.csv\", \"wb\")\n",
    "    positive_cases_file.write(URL_content)\n",
    "    positive_cases_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is purely for the sources of data that include data outside the UK as having international data would mean too much to parse through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(filename):\n",
    "    uk = list()\n",
    "    with open(filename, 'r') as readFile:\n",
    "        reader = csv.reader(readFile)\n",
    "        for row in reader:\n",
    "            if row[0] == \"GBR\" or row[0] == \"iso_code\":\n",
    "                uk.append(row)\n",
    "    \n",
    "    with open(filename, 'w') as writeFile:\n",
    "        writer = csv.writer(writeFile)\n",
    "        writer.writerows(uk)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counts the number of days since the earliest data entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberofdays(date_in_question):\n",
    "    start_date = date(2020, 1, 31)\n",
    "    dateq = date_in_question.split(\"-\")\n",
    "    cdate = date(int(dateq[0]), int(dateq[1]), int(dateq[2]))\n",
    "    return (cdate - start_date).days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will normalise all the data in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_dataframe(df):\n",
    "    for i in range(1, len(df.columns)):\n",
    "        maxi = max(df.iloc[:,i])\n",
    "        mini = min(df.iloc[:,i])\n",
    "        for j in range(len(df.iloc[:,0])):\n",
    "            df.iloc[j, i] = (df.iloc[j, i] - mini)/(maxi-mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will only take columns in the data frame with no NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_NaNs(df):\n",
    "    data = []\n",
    "    for column in df.columns:\n",
    "        temp = [float(i) for i in df[column]]\n",
    "        if np.isnan(np.sum(np.array(temp))):\n",
    "            df.drop([column], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will only take columns that don't have a single repeating entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_repeat(df):\n",
    "    data = []\n",
    "    for column in df.columns:\n",
    "        if df[column].nunique() == 1:\n",
    "            df.drop([column], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_data(\"positive_cases.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabs the current working directory where the csv files are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads the csv files into their respective dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cases_df = pd.read_csv(os.path.join(working_dir, \"positive_cases.csv\"))\n",
    "pos_cases_df.drop(pos_cases_df.iloc[:, 0:3], inplace = True, axis=1)\n",
    "dates = pos_cases_df[\"date\"]\n",
    "pos_cases_df.drop([\"date\"], inplace = True, axis=1)\n",
    "pos_cases_df.drop([\"tests_units\"], inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_NaNs(pos_cases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_repeat(pos_cases_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code just adds a column to the dataframe that counts the number of days since the earliest data entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "daysSince = []\n",
    "for i in range(len(pos_cases_df)):\n",
    "    daysSince.append(i)\n",
    "pos_cases_df[\"daysSince\"] = daysSince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_cases  new_cases  total_cases_per_million  new_cases_per_million  \\\n",
      "0          2.0        2.0                    0.029                  0.029   \n",
      "1          2.0        0.0                    0.029                  0.000   \n",
      "2          2.0        0.0                    0.029                  0.000   \n",
      "3          8.0        6.0                    0.118                  0.088   \n",
      "4          8.0        0.0                    0.118                  0.000   \n",
      "\n",
      "   daysSince  \n",
      "0          0  \n",
      "1          1  \n",
      "2          2  \n",
      "3          3  \n",
      "4          4  \n"
     ]
    }
   ],
   "source": [
    "print(pos_cases_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize all the data in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise_dataframe(pos_cases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "# Input layer\n",
    "NN_model.add(InputLayer())\n",
    "# Hidden Layers\n",
    "NN_modle.add(128, kernel_initializer=\"normal\", activation=\"relu\")\n",
    "NN_modle.add(256, kernel_initializer=\"normal\", activation=\"relu\")\n",
    "NN_modle.add(256, kernel_initializer=\"normal\", activation=\"relu\")\n",
    "NN_modle.add(256, kernel_initializer=\"normal\", activation=\"relu\")\n",
    "# Output layer \n",
    "NN_modle.add(1, kernel_initializer=\"normal\", activation=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
