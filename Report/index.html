<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>report</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="github-markdown.css">
  <style>
    .markdown-body {
      box-sizing: border-box;
      min-width: 200px;
      max-width: 980px;
      margin: 0 auto;
      padding: 45px;
    }

    @media (max-width: 767px) {
      .markdown-body {
        padding: 15px;
      }
    }
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
  <article class="markdown-body">
  <h1 id="sns-assignment-20-21-sn17031141">SNS Assignment 20/21 SN17031141</h1>
  <h1 id="covid-forecasting-engine">Covid Forecasting Engine</h1>
  <h2 id="table-of-contents">Table of Contents</h2>
  <ul>
  <li><a href="#description">Description</a></li>
  <li><a href="#the-packages">The Packages</a></li>
  <li><a href="#the-data">The Data</a></li>
  <li><a href="#the-neural-network-model">The Neural Network Model</a></li>
  <li><a href="#the-results">The Results</a></li>
  <li><a href="#the-conclusion">The Conclusion</a></li>
  <li><a href="#the-appendices">The Appendices</a></li>
  </ul>
  <h2 id="description">Description</h2>
  <p>The problem presented is to design and build a Covid forecasting engine using a neural network. The metric to be forecasted here is the total number of positive cases recorded in the UK. That is to say, the cumulative number of cases in the UK since January 31st of 2020. The solution stated in this report involves building a deep neural network in <code>Python</code> using <code>tensorflow</code> modules and training the model using a section of the data from a regularly updated csv file. The performance of the model is then tested by inputting the previous seven days worth of data, predicting the total number of positive cases the next day and comparing the prediction with the true value taken from the csv file.</p>
  <p>In the following sections of this report, the choice for the source of data will be justified and and any preprocessing involved will be explained. The design of the deep neural network will also be explained and the results will be presented.</p>
  <p>All of the work done for this project can be found on <a href="https://github.com/OliverJaison/SNS_Assignment20-21">Github</a>.</p>
  <h2 id="the-packages">The Packages</h2>
  <pre><code><span class="hljs-title">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing
  <span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
  <span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
  <span class="hljs-keyword">import</span> requests
  <span class="hljs-keyword">import</span> os
  <span class="hljs-keyword">import</span> csv
  <span class="hljs-keyword">import</span> keras
  <span class="hljs-keyword">import</span> tabulate
  <span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
  <span class="hljs-title">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
  <span class="hljs-title">from</span> keras.models <span class="hljs-keyword">import</span> Sequential
  <span class="hljs-title">from</span> keras.layers <span class="hljs-keyword">import</span> Activation
  <span class="hljs-title">from</span> keras.layers <span class="hljs-keyword">import</span> Dropout
  <span class="hljs-title">from</span> keras.layers <span class="hljs-keyword">import</span> InputLayer
  <span class="hljs-title">from</span> keras.layers.core <span class="hljs-keyword">import</span> Dense, Flatten
  <span class="hljs-title">from</span> keras.optimizers <span class="hljs-keyword">import</span> Adam
  <span class="hljs-title">from</span> keras.metrics <span class="hljs-keyword">import</span> categorical_crossentropy
  </code></pre><h2 id="the-data">The Data</h2>
  <p>The csv file is taken from <a href="https://covid.ourworldindata.org/data/owid-covid-data.csv">https://covid.ourworldindata.org/data/owid-covid-data.csv</a>. Initially, the data was taken from the <a href="https://coronavirus.data.gov.uk/api/v1/data?filters=areaType=overview&amp;structure=%7B%22areaType%22:%22areaType%22,%22areaName%22:%22areaName%22,%22areaCode%22:%22areaCode%22,%22date%22:%22date%22,%22newCasesByPublishDate%22:%22newCasesByPublishDate%22,%22cumCasesByPublishDate%22:%22cumCasesByPublishDate%22%7D&amp;format=csv">United Kingdom government website</a>. The difference between the two sources of data is that the former has a significantly larger set of parameters that could perhaps help better train the neural network model. The UK goverment website has only a set of 6 parameters per day one of which is the metric to be predicted. The &quot;ourworldindata&quot; website has over 50 parameters per day. While it is not necessary to use all of these parameters, should the performance of the neural network fall below reasonable accuracy then giving more parameters to learn from can maybe improve results.</p>
  <h3 id="the-preprocessing">The Preprocessing</h3>
  <p>Through the use of the <code>Requests</code> module, a function was made to download the contents csv file from the website and write them into a csv file named <em>positive_cases.csv</em>.</p>
  <pre><code class="lang-py">def update_data():
      positive_cases_csv_URL = <span class="hljs-string">"https://covid.ourworldindata.org/data/owid-covid-data.csv"</span>
      req = requests.<span class="hljs-keyword">get</span>(positive_cases_csv_URL)
      URL_content = req.content
      positive_cases_file = open(<span class="hljs-string">"positive_cases.csv"</span>, <span class="hljs-string">"wb"</span>)
      positive_cases_file.write(URL_content)
      positive_cases_file.close()
  </code></pre>
  <p>This newly written csv file will have Covid data from all over the world. However, for the purposes of this problem, only the data from the UK is needed. Using the <code>csv</code> module, a function was made to remove all non-UK data from the csv file directly. This was chosen to be done over simply removing the data from the dataframe that the csv is imported into because it made debugging the dataframe and the written functions significantly easier than having to reload the csv each runtime. </p>
  <pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">filter_data</span><span class="hljs-params">(filename)</span>:</span>
      uk = list()
      <span class="hljs-keyword">with</span> open(filename, <span class="hljs-string">'r'</span>) <span class="hljs-keyword">as</span> readFile:
          reader = csv.reader(readFile)
          <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> reader:
              <span class="hljs-keyword">if</span> row[<span class="hljs-number">0</span>] == <span class="hljs-string">"GBR"</span> <span class="hljs-keyword">or</span> row[<span class="hljs-number">0</span>] == <span class="hljs-string">"iso_code"</span>:
                  uk.append(row)
  
      <span class="hljs-keyword">with</span> open(filename, <span class="hljs-string">'w'</span>) <span class="hljs-keyword">as</span> writeFile:
          writer = csv.writer(writeFile)
          writer.writerows(uk)
  </code></pre>
  <p>Now that the csv file only had data localized to the UK, the <code>Pandas</code> and <code>os</code> modules are used to import the csv into a dataframe. After this, the first three columns are dropped because the information contained in them is a repeating entry for location and iso code. The date column is also dropped because it is not needed for the neural network input. The dates column is replaced and will be discuss later. The code also shows that a column called <em>tests_units</em> is removed. This is because every entry is just <em>tests_units</em> and these entries cannot be ennumerated. </p>
  <pre><code class="lang-py"><span class="hljs-attr">working_dir</span> = os.getcwd()
  <span class="hljs-attr">pos_cases_df</span> = pd.read_csv(os.path.join(working_dir, <span class="hljs-string">"positive_cases.csv"</span>))
  pos_cases_df.drop(pos_cases_df.iloc[:, <span class="hljs-number">0</span>:<span class="hljs-number">3</span>], <span class="hljs-attr">inplace</span> = True, <span class="hljs-attr">axis=1)</span>
  <span class="hljs-attr">dates</span> = pos_cases_df[<span class="hljs-string">"date"</span>]
  pos_cases_df.drop([<span class="hljs-string">"date"</span>], <span class="hljs-attr">inplace</span> = True, <span class="hljs-attr">axis=1)</span>
  pos_cases_df.drop([<span class="hljs-string">"tests_units"</span>], <span class="hljs-attr">inplace</span> = True, <span class="hljs-attr">axis=1)</span>
  </code></pre>
  <p>Now that the dataframe only has numerical strings as the data entries, the <code>Numpy</code> module is used to ennumerate all the entries and remove and NaN values (empty entries) as well as to remove any columns with a single repeating value. This is done because a constant value will not have an effect on the training of the neural network. Additionally the network cannot accept NaN as an input for training. This removes a great majority of the number of parameters that can be input into the neural network. </p>
  <pre><code class="lang-py">def no_NaNs(df):
      data = []
      <span class="hljs-keyword">for</span> column <span class="hljs-keyword">in</span> df.<span class="hljs-built_in">columns</span>:
          temp = [<span class="hljs-built_in">float</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> df[column]]
          <span class="hljs-keyword">if</span> <span class="hljs-built_in">np</span>.isnan(<span class="hljs-built_in">np</span>.<span class="hljs-built_in">sum</span>(<span class="hljs-built_in">np</span>.<span class="hljs-built_in">array</span>(temp))):
              df.drop([column], inplace=True, axis=<span class="hljs-number">1</span>)
  </code></pre>
  <pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">no_repeat</span><span class="hljs-params">(df)</span>:</span>
      data = []
      <span class="hljs-keyword">for</span> column <span class="hljs-keyword">in</span> df.columns:
          <span class="hljs-keyword">if</span> df[column].nunique() == <span class="hljs-number">1</span>:
              df.drop([column], inplace=<span class="hljs-keyword">True</span>, axis=<span class="hljs-number">1</span>)
  </code></pre>
  <table>
  <thead>
  <tr>
  <th style="text-align:right"></th>
  <th style="text-align:right">total_cases</th>
  <th style="text-align:right">new_cases</th>
  <th style="text-align:right">total_cases_per_million</th>
  <th style="text-align:right">new_cases_per_million</th>
  <th style="text-align:right">stringency_index</th>
  </tr>
  </thead>
  <tbody>
  <tr>
  <td style="text-align:right">0</td>
  <td style="text-align:right">2</td>
  <td style="text-align:right">2</td>
  <td style="text-align:right">0.029</td>
  <td style="text-align:right">0.029</td>
  <td style="text-align:right">8.33</td>
  </tr>
  <tr>
  <td style="text-align:right">1</td>
  <td style="text-align:right">2</td>
  <td style="text-align:right">0</td>
  <td style="text-align:right">0.029</td>
  <td style="text-align:right">0</td>
  <td style="text-align:right">8.33</td>
  </tr>
  <tr>
  <td style="text-align:right">2</td>
  <td style="text-align:right">2</td>
  <td style="text-align:right">0</td>
  <td style="text-align:right">0.029</td>
  <td style="text-align:right">0</td>
  <td style="text-align:right">11.11</td>
  </tr>
  <tr>
  <td style="text-align:right">3</td>
  <td style="text-align:right">8</td>
  <td style="text-align:right">6</td>
  <td style="text-align:right">0.118</td>
  <td style="text-align:right">0.088</td>
  <td style="text-align:right">11.11</td>
  </tr>
  <tr>
  <td style="text-align:right">4</td>
  <td style="text-align:right">8</td>
  <td style="text-align:right">0</td>
  <td style="text-align:right">0.118</td>
  <td style="text-align:right">0</td>
  <td style="text-align:right">11.11</td>
  </tr>
  </tbody>
  </table>
  <p>The table above is a representation of the dataframe so far after all the preprocessing that has been done on it. The index of the dataframe will be used to replace the dates column. It will indicate the number of days since January 31st of 2020. An extra column is also added for the sake of the neural network.</p>
  <pre><code class="lang-py">daysSince = []
  <span class="hljs-keyword">for</span> i in <span class="hljs-keyword">range</span>(<span class="hljs-built_in">len</span>(pos_cases_df)):
      daysSince.<span class="hljs-built_in">append</span>(i)
  pos_cases_df[<span class="hljs-string">"daysSince"</span>] = daysSince
  </code></pre>
  <table>
  <thead>
  <tr>
  <th style="text-align:right">total_cases</th>
  <th style="text-align:right">new_cases</th>
  <th style="text-align:right">total_cases_per_million</th>
  <th style="text-align:right">new_cases_per_million</th>
  <th style="text-align:right">stringency_index</th>
  <th style="text-align:right">daysSince</th>
  </tr>
  </thead>
  <tbody>
  <tr>
  <td style="text-align:right">2</td>
  <td style="text-align:right">2</td>
  <td style="text-align:right">0.029</td>
  <td style="text-align:right">0.029</td>
  <td style="text-align:right">8.33</td>
  <td style="text-align:right">0</td>
  </tr>
  <tr>
  <td style="text-align:right">2</td>
  <td style="text-align:right">0</td>
  <td style="text-align:right">0.029</td>
  <td style="text-align:right">0</td>
  <td style="text-align:right">8.33</td>
  <td style="text-align:right">1</td>
  </tr>
  <tr>
  <td style="text-align:right">2</td>
  <td style="text-align:right">0</td>
  <td style="text-align:right">0.029</td>
  <td style="text-align:right">0</td>
  <td style="text-align:right">11.11</td>
  <td style="text-align:right">2</td>
  </tr>
  <tr>
  <td style="text-align:right">8</td>
  <td style="text-align:right">6</td>
  <td style="text-align:right">0.118</td>
  <td style="text-align:right">0.088</td>
  <td style="text-align:right">11.11</td>
  <td style="text-align:right">3</td>
  </tr>
  <tr>
  <td style="text-align:right">8</td>
  <td style="text-align:right">0</td>
  <td style="text-align:right">0.118</td>
  <td style="text-align:right">0</td>
  <td style="text-align:right">11.11</td>
  <td style="text-align:right">4</td>
  </tr>
  </tbody>
  </table>
  <p>At this point all that is left is for the data to be formatted as an input to a neural network and to split the data into training and testing. The intention is to feed the model seven days worth of data and have it predict the total number of cases on the eighth day. In order to do this a sliding window is created. The size of this window is parameterized but the logic is that it will cover 7 rows in the dataframe (ignoring the first column), add these rows to a list. </p>
  <p>At this point the list is a 2 dimensional array and for simplicity, we want the input to the model to be 2 dimensional, therefore this list is flattened to become 1 dimensional. This then flattened list is appended to the feature matrix. Similarly, the row exactly n increments from the sliding window is added to the labels matrix. The parameter n is the number of days in advance the model will attempt to forecast. This means that a new feature and label matrix will have to be generated for a new value of n and the model will have to be trained again on these new matrices. </p>
  <pre><code class="lang-py">def create_features(df, window_size, forecast):
      <span class="hljs-built_in">features</span> = []
      <span class="hljs-built_in">labels</span> = []
      i = window_size;
      <span class="hljs-keyword">while</span> i &lt; len(df.iloc[:, <span class="hljs-number">0</span>]) - forecast-<span class="hljs-number">1</span>:
          window = df.iloc[i - window_size: i, <span class="hljs-number">1</span>:]
          window = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">array</span>(window)
          window = window.<span class="hljs-built_in">flatten</span>()
          <span class="hljs-built_in">labels</span>.<span class="hljs-built_in">append</span>(df.iloc[i + forecast, <span class="hljs-number">0</span>])
          <span class="hljs-built_in">features</span>.<span class="hljs-built_in">append</span>(window)
          i += <span class="hljs-number">1</span>
      <span class="hljs-built_in">features</span> = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">array</span>(<span class="hljs-built_in">features</span>)
      <span class="hljs-built_in">labels</span> = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">array</span>(<span class="hljs-built_in">labels</span>)
      <span class="hljs-built_in">return</span> <span class="hljs-built_in">features</span>, <span class="hljs-built_in">labels</span>
  </code></pre>
  <p>The feature and label matrices are then split using <code>Numpy</code> with a 80:20 split.</p>
  <pre><code class="lang-py">training_features1, testing_features1 = np.<span class="hljs-built_in">split</span>(features1, [<span class="hljs-built_in">int</span>(<span class="hljs-number">0.8</span>*<span class="hljs-built_in">len</span>(features1))])
  training_labels1, testing_labels1 = np.<span class="hljs-built_in">split</span>(labels1, [<span class="hljs-built_in">int</span>(<span class="hljs-number">0.8</span>*<span class="hljs-built_in">len</span>(labels1))])
  </code></pre>
  <h2 id="the-neural-network-model">The Neural Network Model</h2>
  <p>As stated before, the chosen architecture for this project is a dense neural network model. Neural networks are commonly used for classification problems such as gender detection or symbol classification. The problem faced here is a regression problem because there are no discrete metrics being looked at, all the parameters are continuous. </p>
  <p>This means that common practices such as one hot encoding the input or output will not work here. The dense neural network architecture is the simplest by far, only using a series of dense layers for both input and hidden layers. The specific structure is shown below:</p>
  <pre><code class="lang-py">input_shape = training_features1.<span class="hljs-keyword">shape[1]
  </span>
  NN_model = Sequential()
  <span class="hljs-comment"># Input layer</span>
  NN_model.<span class="hljs-keyword">add(Dense(128, </span>input_dim=input_shape, kernel_initializer=<span class="hljs-string">"normal"</span>, activation=<span class="hljs-string">"relu"</span>))
  <span class="hljs-comment"># Hidden Layers</span>
  NN_model.<span class="hljs-keyword">add(Dense(256, </span>kernel_initializer=<span class="hljs-string">"normal"</span>, activation=<span class="hljs-string">"relu"</span>))
  NN_model.<span class="hljs-keyword">add(Dense(256, </span>kernel_initializer=<span class="hljs-string">"normal"</span>, activation=<span class="hljs-string">"relu"</span>))
  NN_model.<span class="hljs-keyword">add(Dense(256, </span>kernel_initializer=<span class="hljs-string">"normal"</span>, activation=<span class="hljs-string">"relu"</span>))
  <span class="hljs-comment"># Output layer </span>
  NN_model.<span class="hljs-keyword">add(Dense(1, </span>kernel_initializer=<span class="hljs-string">"normal"</span>, activation=<span class="hljs-string">"linear"</span>))
  
  NN_model.compile(loss=<span class="hljs-string">"mean_absolute_error"</span>, optimizer=<span class="hljs-string">"adam"</span>, metrics=[<span class="hljs-string">"accuracy"</span>])
  NN_model.summary()
  </code></pre>
  <hr>
  <p>Layer (type)                 Output Shape              Param #<br>----------------------------------------------------------------:
  dense_1 (Dense)              (None, 128)                4608<br>dense_2 (Dense)              (None, 256)               33024<br>dense_3 (Dense)              (None, 256)               65792<br>dense_4 (Dense)              (None, 256)               65792<br>dense_5 (Dense)              (None, 1)                   257       </p>
  <p>Total params: 169473,
  Trainable params: 169473,
  Non-trainable params: 0</p>
  <pre><code class="lang-py"><span class="hljs-attr">history1</span> = NN_model.fit(
      training_features1, 
      training_labels1, 
      <span class="hljs-attr">epochs=500,</span> 
      <span class="hljs-attr">validation_split=0.2</span>
      )
  </code></pre>
  <p>The activation function for the output layer is made to be linear because this is a regresson problem and the numerical values of the output are what is important. Within the hidden layer, ReLu is used as the activation function because it is simple and cheap in terms of processing power. Additionally, we will eventually get quite large inputs looking at later entries of the data set so it would be best if the slope does not saturate. </p>
  <h2 id="the-results">The Results</h2>
  <p>One problem that was encountered with compiling the model was that accuracy was not the best metric to use. Due to the problem being of regressive nature rather than classification, the model can make a prediction with only 0.5% error and the accuracy would still be zero because the prediction is not exactly correct. This would mean that even after training for over 500 epochs, the training and validation accuracy will remain poor. This can be seen in the following graphs:</p>
  <p><img src="Training_1_day.PNG" alt="Training for 1 day forecast" title="Title"></p>
  <p>One way around this was to plot the true values against the predicted values and record the percentage error and use this as relative accuracy.</p>
  <pre><code class="lang-py"><span class="hljs-attr">x</span> = [i for i in range(int(testing_features1[<span class="hljs-number">0</span>,-<span class="hljs-number">1</span>]+<span class="hljs-number">1</span>), int(testing_features1[-<span class="hljs-number">1</span>,-<span class="hljs-number">1</span>]+<span class="hljs-number">2</span>))]
  <span class="hljs-attr">y</span> = testing_labels1
  <span class="hljs-attr">x_pred</span> = testing_features1
  <span class="hljs-attr">y_pred</span> = NN_model.predict(x_pred)
  <span class="hljs-attr">err1</span> = np.abs(y - y_pred)
  <span class="hljs-attr">acc1</span> = np.<span class="hljs-literal">on</span>es(len(y)) - np.divide(err1, y)
  <span class="hljs-attr">acc_bar1</span> = np.mean(acc1)
  </code></pre>
  <p><img src="Error_1_day.PNG" alt="Error between True and Predicted Values for 1 day forecast" title="Title"></p>
  <p>The feature and label matrices are regenerated for 2, 5, 10, 20 and 50 day forecasts and the model is trained against each of these datasets to show the performance.</p>
  <p><img src="Results.PNG" alt="Table of Results"></p>
  <h2 id="the-conclusion">The Conclusion</h2>
  <p>The project involved using machine learning techniques to forecast the cumulative number of Covid cases in the UK. The data was imported from the <a href="https://covid.ourworldindata.org/data/owid-covid-data.csv">Our World in Data</a> website and preprocessed by removing non-UK data entries and all columns with NaN values as well as all columns with constant repeating data entries. This data was then flattened and split with 80:20 splitting and used to train a Deep Neural Network model. The performance of the model gradually gets worse with more the more days in advance it attempts to forecast. The best possible average accuracy being 84.86%.</p>
  <h2 id="the-appendices">The Appendices</h2>
  <p><img src="Error_1_day.PNG" alt="Error for 1 day in advance">
  <img src="Training_1_day.PNG" alt="Training for 1 day in advance"></p>
  <p><img src="Error_2_day.PNG" alt="Error for 2 day in advance">
  <img src="Training_2_day.PNG" alt="Training for 2 day in advance"></p>
  <p><img src="Error_5_day.PNG" alt="Error for 5 day in advance">
  <img src="Training_5_day.PNG" alt="Training for 5 day in advance"></p>
  <p><img src="Error_10_day.PNG" alt="Error for 10 day in advance">
  <img src="Training_10_day.PNG" alt="Training for 10 day in advance"></p>
  <p><img src="Error_20_day.PNG" alt="Error for 20 day in advance">
  <img src="Training_20_day.PNG" alt="Training for 20 day in advance"></p>
  <p><img src="Error_50_day.PNG" alt="Error for 50 day in advance">
  <img src="Training_50_day.PNG" alt="Training for 50 day in advance"></p> 
</article> 
</body>
</html>
