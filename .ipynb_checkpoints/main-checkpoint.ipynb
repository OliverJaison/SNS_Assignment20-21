{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs4\n",
    "from datetime import date\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import csv\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import InputLayer\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulls data from websites and stores them in csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data():\n",
    "    positive_cases_csv_URL = \"https://covid.ourworldindata.org/data/owid-covid-data.csv\"\n",
    "    req = requests.get(positive_cases_csv_URL)\n",
    "    URL_content = req.content\n",
    "    positive_cases_file = open(\"positive_cases.csv\", \"wb\")\n",
    "    positive_cases_file.write(URL_content)\n",
    "    positive_cases_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is purely for the sources of data that include data outside the UK as having international data would mean too much to parse through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(filename):\n",
    "    uk = list()\n",
    "    with open(filename, 'r') as readFile:\n",
    "        reader = csv.reader(readFile)\n",
    "        for row in reader:\n",
    "            if row[0] == \"GBR\" or row[0] == \"iso_code\":\n",
    "                uk.append(row)\n",
    "    \n",
    "    with open(filename, 'w') as writeFile:\n",
    "        writer = csv.writer(writeFile)\n",
    "        writer.writerows(uk)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counts the number of days since the earliest data entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberofdays(date_in_question):\n",
    "    start_date = date(2020, 1, 31)\n",
    "    dateq = date_in_question.split(\"-\")\n",
    "    cdate = date(int(dateq[0]), int(dateq[1]), int(dateq[2]))\n",
    "    return (cdate - start_date).days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will normalise all the data in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_dataframe(df):\n",
    "    for i in range(1, len(df.columns)):\n",
    "        maxi = max(df.iloc[:,i])\n",
    "        mini = min(df.iloc[:,i])\n",
    "        for j in range(len(df.iloc[:,0])):\n",
    "            df.iloc[j, i] = (df.iloc[j, i] - mini)/(maxi-mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will only take columns in the data frame with no NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_NaNs(df):\n",
    "    data = []\n",
    "    for column in range(len(df.columns)):\n",
    "        temp = [float(i) for i in df.iloc[:, column]]\n",
    "        if not np.isnan(np.sum(np.array(temp))):\n",
    "            data.append(temp)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data() \n",
    "filter_data(\"positive_cases.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabs the current working directory where the csv files are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads the csv files into their respective dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cases_df = pd.read_csv(os.path.join(working_dir, \"positive_cases.csv\"))\n",
    "pos_cases_df.drop(pos_cases_df.iloc[:, 0:3], inplace = True, axis=1)\n",
    "dates = pos_cases_df[\"date\"]\n",
    "pos_cases_df.drop([\"date\"], inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-73dc45e081a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mno_nans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mno_NaNs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_cases_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-e9010b4bb6e0>\u001b[0m in \u001b[0;36mno_NaNs\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\.conda\\envs\\sns\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2241\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[1;32m-> 2242\u001b[1;33m                           initial=initial, where=where)\n\u001b[0m\u001b[0;32m   2243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\.conda\\envs\\sns\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "no_nans = no_NaNs(pos_cases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iso_code', 'continent', 'location', 'date', 'total_cases', 'new_cases', 'total_cases_per_million', 'new_cases_per_million', 'population', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'hospital_beds_per_thousand', 'life_expectancy', 'human_development_index']\n"
     ]
    }
   ],
   "source": [
    "print(no_nans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize all the data in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise_dataframe(pos_cases_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code just adds a column to the dataframe that counts the number of days since the earliest data entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daysSince = []\n",
    "for i in range(len(pos_cases_df)):\n",
    "    daysSince.append(i)\n",
    "pos_cases_df[\"daysSince\"] = daysSince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     total_cases  new_cases  new_cases_smoothed  total_deaths  new_deaths  \\\n",
      "406    4261398.0     6684.0            5944.286      125579.0       176.0   \n",
      "407    4267015.0     5617.0            5872.714      125701.0       122.0   \n",
      "408    4271710.0     4695.0            5792.000      125753.0        52.0   \n",
      "409    4276840.0     5130.0            5835.857      125817.0        64.0   \n",
      "410    4282203.0     5363.0            5763.571      125927.0       110.0   \n",
      "\n",
      "     new_deaths_smoothed  total_cases_per_million  new_cases_per_million  \\\n",
      "406              154.857                62772.851                 98.459   \n",
      "407              149.571                62855.592                 82.742   \n",
      "408              145.286                62924.753                 69.160   \n",
      "409              145.143                63000.320                 75.568   \n",
      "410              127.857                63079.320                 79.000   \n",
      "\n",
      "     new_cases_smoothed_per_million  total_deaths_per_million  ...  \\\n",
      "406                          87.563                  1849.851  ...   \n",
      "407                          86.508                  1851.648  ...   \n",
      "408                          85.320                  1852.414  ...   \n",
      "409                          85.966                  1853.357  ...   \n",
      "410                          84.901                  1854.977  ...   \n",
      "\n",
      "     gdp_per_capita  extreme_poverty  cardiovasc_death_rate  \\\n",
      "406       39753.244              0.2                122.137   \n",
      "407       39753.244              0.2                122.137   \n",
      "408       39753.244              0.2                122.137   \n",
      "409       39753.244              0.2                122.137   \n",
      "410       39753.244              0.2                122.137   \n",
      "\n",
      "     diabetes_prevalence  female_smokers  male_smokers  \\\n",
      "406                 4.28            20.0          24.7   \n",
      "407                 4.28            20.0          24.7   \n",
      "408                 4.28            20.0          24.7   \n",
      "409                 4.28            20.0          24.7   \n",
      "410                 4.28            20.0          24.7   \n",
      "\n",
      "     handwashing_facilities  hospital_beds_per_thousand  life_expectancy  \\\n",
      "406                     NaN                        2.54            81.32   \n",
      "407                     NaN                        2.54            81.32   \n",
      "408                     NaN                        2.54            81.32   \n",
      "409                     NaN                        2.54            81.32   \n",
      "410                     NaN                        2.54            81.32   \n",
      "\n",
      "     human_development_index  \n",
      "406                    0.932  \n",
      "407                    0.932  \n",
      "408                    0.932  \n",
      "409                    0.932  \n",
      "410                    0.932  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pos_cases_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
